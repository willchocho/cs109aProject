{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109a\n",
    "\n",
    "# Final Project - Alzheimer's Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Statement:\n",
    "\n",
    "Our project question is: Which factors for a patient are most important in predicting his or her likelihood of having Alzheimer's?  Specifically, we are only able to utilize limited patient data, and want to develop the optimal model (using as little data as possible, given that there can be extensive costs for obtaining each measure), for the least expensive detection of Alzheimer’s. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation:\n",
    "\n",
    "According to Alzheimer's Association (alz.org), current methods of detection for Alzheimer's includes a complete medical assessment, which requires a physician visit. As there is no one test that enables an individual to determine if he or she has Alzheimer's, the overall process is currently very expensive, and could include a review of medical history, mood testing, a physical exam, a neurological exam, and other blood and brain tests (Alzheimer's Association). Furthermore, diagnosing Alzheimer's specifically is more costly and difficult than diagnosing for dementia.\n",
    "\n",
    "Despite that a physician is currently estimated to be able to diagnose Alzheimer's with over 90% accuracy, this often requires the input of neurologists, psychiatrists, and psychologists and can thus be extremely costly for the patient (Alzheimer's Association). A envisionable goal for future diagnoses processes would be to utilize as few input variables as possible to still accurately diagnose a patient.\n",
    "\n",
    "Given that the onset of Alzheimer's cannot be reversed or halted, the goal of our model is to assign costs to each of the factors in the data, to determine the lowest cost model for diagnosis given a patient's medical history and clinical exam variables (Alzheimer's Association). Providing a classification model that utilizes as few variables as possible could enable cheaper and earlier detection, allowing patients to better prepare for treatment and planning with their families."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "Note: For an overview of the costs of obtaining each of the input variables, see the EDA page.\n",
    "\n",
    "From our EDA, we can confirm that we must make indicator variables corresponding to certain categorical variables in the data. Additionally, there appears to be a difference in risk of developing Alzheimer’s between demographics; demographic factors are thus important in determining risk of Alzheimer’s. Our EDA further demonstrates the potential for sex, ethnicity, marital status, and other demographic factors to be significantly correlated with diagnosis of Alzheimer's. Furthermore, looking at the heatmap, groups of factors associated to tests for cognitive impairment are seen to be relatively highly correlated. Thus, our goal with this project is to determine the most relevant factors for Alzheimer's classification, such that our model is accurate in predicting a patient's likelihood of having Alzheimer’s, but is also inexpensive as possible.\n",
    "\n",
    "We extend this project question by examining, given a set of costs for each of the detection factors (predictors), what is the cheapest feasible model for Alzheimer's classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction and Description of Data\n",
    "\n",
    "The data we use is from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database, and includes a large collection of patient information including demographics and genetics, lifestyle factors, medical history, lab records such as blood biomarkers, imaging data such as MRI and PET images, and cognitive test scores. In addition, we have the diagnostic categories for each patient (AD, MCI, and Normal, where AD indicates presence of Alzheimer’s disease, and MCI is mild cognitive impairment).\n",
    "\n",
    "\n",
    "An important characteristic of our data is that there are 94 variables per observation, but there are many missing values. This is an issue that will have to be addressed in our model- we can delete observations with missing values, impute missing values using values such as means, or impute missing values using a model. We will not want to simply delete observations with missing values because most observations do not have all 94 variables, and it is crucial that we do not bias the data that we use to make our model; it is possible that patients who are missing values for certain predictors are similar in some way, such as being from a low income town with a low amenity hospital that does not measure certain predictors. Therefore in our model, we will impute missing values.\n",
    "\n",
    "\n",
    "The 94 variables of the dataset are diverse; some variables capture physiological measures, while some are simply unique ID numbers. In our model, we will not use most of the uniquely identifying variables such as Patient ID number. Further, some of the variables are categorical or binary, or may not be recorded as so but conceptually are; for these variables we created indicator variables. For variables we deem necessary, we included interaction variables in addition to the individual variables themselves.\n",
    "\n",
    "The variables that we will use in our models are listed as follows:\n",
    "\n",
    "age_at_examdate, PTGENDER_Female, PTRACCAT_Am Indian/Alaskan, PTRACCAT_Asian, PTRACCAT_Black, PTRACCAT_Hawaiian/Other PI, PTRACCAT_More than one, PTRACCAT_Unknown, PTMARRY_Divorced, PTMARRY_Married, PTMARRY_Unknown, PTMARRY_Widowed, PTEDUCAT_12, PTEDUCAT_14, PTEDUCAT_16, PTEDUCAT_18, PTEDUCAT_19, PTEDUCAT_20, APOE, EcogSPMem, EcogSPLang, EcogSPVisspat, EcogSPPlan, EcogSPOrgan, EcogSPDivatt, Ventricles, Hippocampus, WholeBrain, Entorhinal, Fusiform, MidTemp, ICV, COLPROT_ADNI1, COLPROT_ADNI2, COLPROT_ADNI3, CDRSB, ADAS11, MMSE, RAVLT_immediate, RAVLT_learning, RAVLT_forgetting, RAVLT_perc_forgetting, FAQ, MOCA\n",
    "\n",
    "\n",
    "These can be divided into categories such as demographic predictors (age, gender, ethnicity, marital status, and education dummy variables), the predictor for APOE (the presence level of Apolipoprotein E - a regulator of lipid metabolism that impacts women more than men for AD development (Hara 2017, Cognitive Vitality)), Everyday Cognition predictors (a survey with several subscales), MRI-dependent predictors, data collection protocal (COLPROT), CDRSB score (Clinical Dementia Rating Scale Sum of Boxes), ADAS11 score (Alzheimer's Disease Assessment Scale 11), MMSE score (Mini Mental State Examination), RAVLT score (Rey's Auditory Verbal Learning Test), FAQ (Functional Activities Questionnaire), and the MOCA score (Montreal Cognitive Assessment for the diagnosis of Alzheimer's disease and other dementias).\n",
    "\n",
    "These stand out as good predictors due to the literature on Alzheimer's detection, and a better understanding of the validity of each of the measures. These groups of variables, from brain imaging factors, survey data, and more, have been studied in the literature on Alzheimer's detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literature Review and Related Work\n",
    "\n",
    "Alzheimer’s Disease (AD) is a progressive brain disease in which brain cells degenerate and die, impairing the patient of cognitive function, and often leads to dementia, a condition which is characterized by the loss of intellectual and social skills (Mayo Clinic). Alzheimer’s disease is diagnosed by assessments performed by neurologists and psychologists. Neurologists can diagnose Alzheimer’s and its physiological progression through MRI and calculations of brain volumes, whereas psychologists can diagnose Alzheimer’s and its functional progression through cognitive assessments.\n",
    "\n",
    "The challenges involved in diagnosing AD includes sensitivity, which is the rate of true positives in diagnosis, and specificity, which is the rate of true negatives in diagnosis. An increase in sensitivity is required to properly diagnose AD patients with AD, but it comes at the cost of a decrease in specificity, which is the misdiagnosis of a healthy patient as an AD patient.\n",
    "\n",
    "Physiological progression can be determined by the measurement of brain volumes through MRI, but also through alternate methods such as genetics and protein concentration measurement. AD causes notable changes in brain dimensions. The progressive shrinkage of the total brain volume of patients is a key variable used in the diagnosis of AD progression. Notably, the size of the hippocampus, part of the brain that influences the memory capacity of the brain, is an important biomarker for the progression of AD. (Vemuri et al.) Furthermore, proteins such as APOE4 have been recently discovered to be significant markers for AD. For example, “The allele ε4 of apolipoprotein E4 (APOE ε4), is the most prevalent genetic risk factor for sporadic AD, and is expressed in more than half of the AD patients” (Michaelson). Nazeri et al. noted additional proteins that together can diagnose AD with 57% specificity and 89% sensitivity (Nazeri et al.).\n",
    "\n",
    "On the other hand, functional progression can be determined by the measurement of cognitive functions in various tasks such as memory, vision, and speech. These measurements are performed through standardized tests that have specific monitored tasks, or surveys. Standardized tests include the Alzheimer’s Disease Assessment Scale (ADAS), specifically the ADAS-Cog, the Montreal Cognitive Assessment (MoCA), the Mini-Mental State Examination (MMSE), Rey's Auditory Verbal Learning Test (RAVLT). Surveys include the Clinical Dementia Rating Scale Sum of Boxes (CDRSB), the Everyday Cognition Scale (ECog), Functional Activities Questionnaire (FAQ). These assessments include tasks that are based on cognitive function categories specified in psychology, and each assessment assesses and weighs the tasks differently. For example, Park et al. have found that AD patients are more likely to have greater deficits in Everyday Visuospatial Functioning than patients with Frontotemporal Degeneration Disease, another brain disease (Park et al.). Consequently, the assessments have had varying degrees of success. For example, the ADAS-Cog has been noted to be insufficiently accurate and reliable (Karin et al.), whereas the MoCA has been shown to have a sensitivity of 0.94 but a specificity less than 0.60, and the RAVLT has been shown to be able to diagnose AD early on.\n",
    "\n",
    "Additionally, other studies have demonstrated the reliability and interactivity of the variables. For example, it has been noted that the risk in developing AD in patients with the APOE ε4 allele is greater in females than in males, suggesting an interaction effect between sex and APOE ε4 gene (Ungar et al.). Rueda et al. have found that informant-reported values of the ECog assessment are more reliable than self-reported values, suggesting ECog results of the study partners are more reliable than the subject values (Rueda et al.), and Pradier et al. have found that in the French National Alzheimer database, age, education, gender and even place of residence affect the MMSE results, suggesting interaction (Pradier et al.).\n",
    "\n",
    "Most of the assessments above are not AD specific but rather adept at evaluating the cognitive capacity of patients. For example, the FAQ is a survey not specifically for AD, but rather separates subjects into normal or impaired function. Neurologists and psychologists currently rely on a selection of these assessments in order to diagnose AD. However, there are efforts to develop models that predict AD using multiple of these assessments. For example, Llano et al. implemented a Random Forest tree-based multivariate models using the ADNI data, in which they found that the model using the ADAS-13 is comparable in accuracy to the model using MRI and other data in predicting the progression of Mild Cognitive Impairment to Alzheimer’s Disease (Llano et al.).\n",
    "\n",
    "Note: see end for Works Cited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "\n",
    "Starting out with EDA enabled us to gain insight into the types of demographic factors that could be significant, as well as potential tests and survey scores that seemed to be effective in the diagnosis of Alzheimer's. \n",
    "\n",
    "\n",
    "Merging this full dataset, ADNIMERGE, with a dataset TOMM40.csv from the ADNI website, we were able to additionally look at the relevance of TOMM40_A1 and TOMM40_A2, which are both alleles for a gene assessment. This dataset TOMM40.csv does not have the full set of unique patient IDs that the master dataset, ADNIMERGE, does. In the process of merging, we choose to drop any patient observations where the ID is not included in the master. Although we want to be cautious when dropping data in any case, there was no other choice in this instance, since we have patients for whom there is no other information than the two alleles, TOMM40_A1 and TOMM40_A2. We are unable to utilize other information to impute missing values, since there is no other information besides the two new predictors of the alleles.\n",
    "\n",
    "Moving forward with a dataset including variables from ADNIMERGE, as well as two new alleles, we create binary indicator variables for the categorical variables of interest. We will do so for gender, education, race, marital status, and the protocol under which the data was collected. We transformed the education level of the patient to a binary variable as we intuitively did not believe that the effect of education level on the outcome was constant for each increase.\n",
    "\n",
    "One valuable variable that was not in our dataset was the age of the patient at the time of the observation. However, the dataset includes the baseline age, and the number of years since the baseline, and so by adding those two variables, a variable corresponding to the age of the patient at the time of the observation was created.\n",
    "\n",
    "Our first try for a model was to create a model that predicted the likelihood of a given individual developing Alzheimer's given their medical history. However, upon exploring our dataset, we found that there was not a reliable record of people's Alzheimer's diagnosis after the baseline, and therefore we could not have a record of patients who began without Alzheimer's and then eventually went on to develop it. Therefore, our presented model is not predicting the likelihood of a patient developing Alzheimer's given their medical history, but is instead predicting the likelihood that a patient has Alzheimer's given their medical history.\n",
    "\n",
    "\n",
    "Imputation:\n",
    "\n",
    "An important characteristic of our dataset is that there are 94 variables per observation, but there are many missing values. This is an issue that will have to be addressed in our model- we can delete observations with missing values, impute missing values using values such as means, or impute missing values using a model. We chose to impute rather than to remove the participants or predictors with missing values for two main reasons. The first main reason is that a majority of our predictors have missing values; therefore by simply removing predictors with missing values severely depletes our data and throws away valuable information about the patients. The second main reason is that the majority of participants have missing values for some of the predictors. Therefore removing observations with missing values is not practical to build a model. Another important aspect of removing missing values is that such a methodology makes sense when it is unlikely that the fact that the observation is missing is unrelated to the outcome variable. We cannot be sure of this since the fact that certain particpants are missing certain observations could be correlated with the outcome variable. For instance, perhaps those who are missing certain medical measurements reside in low income areas with poorly equipped hospitals. And perhaps Alzheimer's is more rampent in low income areas. Then, by deleting out participants with missing variables, we lose an important part of the story. Therefore we will refrain from this.\n",
    "\n",
    "We explored two methods of imputing values: imputation using the mean for each patient, and imputation using a model across patients. First, we spit the dataset before imputation to make sure that our model for imputation in the training set does not use information from the test set. Should we utilize imputation prior to the split, we would be using test data to determine imputation of training data, and vice versa. The test data should be considered a separate data set, for the sole purpose of testing on unknown data later on, after building the model. Thus, imputation should be done on the training and test sets separately. We split the data using patient ID; because our data is longitudinal, we randomly sampled from the list of unique patient IDs to determine which participants will be used for the training set and which will be used for the test set.\n",
    "\n",
    "Imputation using patient level means loops over every unique participant ID in the dataset and imputes missing values of the variable of interest by taking the mean of the patient's other observations; if the patient does not have any observations for the variable of interest (all are nans), then they are left as nans. Therefore imputing using patient-level means does not entirely address the issue of missing values because while we will be able to impute values for patients who have historical data for the variable of interest, those with all missing values will still be left with nans. In fact, the implication of this model is that when applying the model to future patients, the model will only work for participants with a complete set of predictor values; future patients who do not have any values for the predictors in our model cannot be used as we do not have a way to impute using other patients' information. This is the motivation to use an across-patient model for imputation; by using information from other patients to predict values for a given patient, we do not require that future patients will have all predictor values as we can predict missing ones using the model formed from the other patients.\n",
    "\n",
    "In imputing using a model, we tried a methodology that would fit a model based off the training set in order to use for the test set, such that we would not be peeking at the test data for any aspect of creating the model. We would order the columns of imputation from those with the least missing data to most missing data. This ordering is important as we would want our imputation model to rely on as much information as possible in predicting each missing value. An iterative process would enable use of predictors that are less missing, and as these values are imputed, to include the now full predictors in imputing the remaining values. Thus, it makes most sense to begin imputing with the least sparse variables, and finish with the most information for those that are most sparse.\n",
    "\n",
    "However, we found that the data has enough missing values that this method does not work, since a model fitted on the training set is unable to predict given the missing rows in a column for the test set. Thus, we have chosen to move on with mean imputation, despite its limitations as previously discussed, due to the constraints of the data set.\n",
    "\n",
    "In applications of our model to future results, we could impute observations for missing values using aggregate means.\n",
    " \n",
    "After imputation, we scale the continuous variables in the test and training sets separately; we scale to ensure that the varying magnitudes of the predictors do not bias our results. After scaling, we checked how balanced our dataset was, in terms of our outcome variable- whether the patient had Alzheimer's or not. Intuitively, we guessed that our dataset would be unbalacned because the frequency of Alzheimer's is not 50%. As predicted, our dataset was heavily unbalanced as there are a significantly greater proportion of obervations of patients who do not have alzheimers than that of those who do. Therefore, in our analysis, we did not consider the classification accuracy because the composition of our sample can skew interpretation. For instance, a model that simply predicts all observations as not having alzheimers will have a very high accuracy score; but it can be costly not to detect alzheimers and thus we valued a model that has a high true positive rate. Therefore we used the ROC AUC score when comparing across models.\n",
    "\n",
    "Classification Model:\n",
    "\n",
    "In our model, we used the non-baseline values for the physiological measures, cognitive test results, and demographic information. We did not use the baseline values as the baseline visit already incorporates the baseline information, and since the datasets were separated by patient ID and not by observation, every patient observation is included. This left us with 44 predictors, and using these predictors, we created the training set and test set for predictors. A check on shape confirmed that the sizes of the two datasets were roughly similar.\n",
    "\n",
    "We explored a variety of models to compare. We fitted each model to the training set, and compared the ROC AUC score for the training and test sets across models:\n",
    "1. Multinomial Logistic Regression\n",
    "2. Linear Discriminant Analysis (LDA)\n",
    "3. Quadratic Discriminant Analysis (QDA)\n",
    "4. Decision Tree Analysis\n",
    "5. Support Vector Machine (SVM)\n",
    "6. Random Forest\n",
    "7. Bagging Classifier\n",
    "\n",
    "For the decision tree model, we selected the optimal tree depth using cross validation. With this selected optimal tree depth, we defined our decision tree model. \n",
    "\n",
    "For the Random Forest model, we explored the effect of varying max depth for our data. We tested the values [25,30,35,40,45,50,75,100], and we fitted a random forest model 10 times for each value to test, and compared the average ROC AUC curve for the 10 models. Then, we compared across value for both attributes. The exact results of this process change every time it is run because Random Forest performs a random bootstrapping on our data, where each tree uses a different (bootstrap) sample from the data.\n",
    "\n",
    "Thus, using the cases that were left out, we can essentially have classification for a set for the left-out cases. (Approximately 33% of samples are never used, and this can be the out-of-sample validation set to then test). At the end, the class that received the most number of votes in out-of-bag cases is used to find the OOB error: the incorrect number of predictions, averaged over all possible cases, is OOB error. We look at the OOB error rate, or out-of-bag error, to see the prediction error for the Random Forest model. OOB error gives us the average prediction error for each of the training samples, and utilizing it removes the need for a validation set as previously explained; thus, for random forest models, we are able to get estimates of the test set error.\n",
    "\n",
    "Further, we performed a quick test of relative variable importance on our Random Forest model and Bagging Classifier to get a sense as to which variables were contributing most to our data. For both models, the age at exam date appeared to be the signifiantly most important predictor of the model.\n",
    "\n",
    "Comparing test set and training set ROC AUC scores across models, we find the highest test set score with the Random Forest Classifier, with approximate score of 0.516. The LDA model was the second highest, with a very similar test set accuracy score of 0.506. We will discuss the limitations of utilizing a Random Forest Model below, but will now extend our methodology to make the classification model more realistic.\n",
    "\n",
    "\n",
    "Classifying while Acknowledging Costs:\n",
    "\n",
    "Going forward with a classification model, in which the outcome variable represents the likelihood a person with the given values for regressors has Alzheimer's, we explored the estimated costs that each predictor is associated with. For instance, an MRI measure takes more money and time to collect than demographic data. For both the hos|pital and patient, this is important when considering the cost benefit tradeoffs. Using this cost fuction, we model the tradeoff between an accurate classification and cost, given that metrics such as brain imaging measures and biomarkers are often extremely costly to obtain. We want to find the model with the lowest cost possible by utilizing less expensive features, but also be accurate enough as to not incur misdiagnosis costs.\n",
    "\n",
    "It is important to note that we estimated costs through online research, but the results of this can differ as costs of each predictor for the hospital of interest vary. Therefore the results of our model are not robust to changes in cost. However, the process of obtaining the results is; therefore simply by changing the cost values used in our algorithm, we can obtain the applicable results.\n",
    "\n",
    "Given a certain budget, we can determine the optimal predictor categories to use, based on the maximum ROC AUC score on the test set.\n",
    "\n",
    "We proceeded with a linear discriminant analysis model because we determined it the optimal model in the previous part.\n",
    "\n",
    "In this section, we separated the predictors into categories such that the categories were similar in the steps it would take a hospital to collect the information for the predictors. We had 11 different categories: demographic, APOE test, ECOG tests, MRI results, exam procedure, CDRSB results, ADAS results, MMSE results, RAVLT results, FAQ results, and MOCA results. We separated out the different survey and test predictors as the costs associated with each of them differ. The motivation for assigning costs to groups of predictors instead of each predictor is that many predictors have a fixed base cost, and once one variable in a group is collected, the cost to collect the rest is trivial. For instance, in once a single predictor that requires an MRI is used, then the cost of using an MRI is paid, and then the additional cost of the other MRI predictors becomes trivial. While this can be an oversimplification of cost, this simple model provides a rough estimated cost benefit analysis. We estimated the costs through online research, but the costs as defined in our process can be changed to find the applicable results for a hopsital with different associated costs for each predictor category.\n",
    "\n",
    "We then found every possible unique combination of each predictor category. We found there to be 2048. For each unique combination, we fitted the LDA model using the predictors associated with the categories in the combination, and recorded the associated test set and training set ROC AUC scores as well as the cost of using the predictors. Through this methodology, we calculated the monetary costs and accuracy benefits of each possible combination of predictor categories.\n",
    "\n",
    "A scatterplot of ROC AUC score on estimated costs such that each point represents a unique combination of predictor categories represents the cost-benefit tradeoff. The first plot, which uses training set scores, depicts the model improving as cost goes up, which can in some part be attributed to overfitting; increased number of predictors can imply increased cost, and increasing the number of predictors can overfit our model to the training set. The notion of overfitting can also be seen in the scatterplot using the test set scores as the highest test set ROC AUC scores are lower for the greater costs (i.e. above \\$2000) than that of the lower cost range (i.e. below \\$2000).\n",
    "\n",
    "Additionally, our analysis can now output the optimal set of predictors given a budget. For instance, if the budget is \\$2000, we find that our optimal set of predictor categories to use is ['demographic_predictors', 'APOE_predictor', 'ECOG_predictors', 'indicator_predictor', 'CDRSB_predictor', 'ADAS11_predictor', 'MMSE_predictor', 'RAVLT_predictor', 'MOCA_predictor']\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations:\n",
    "\n",
    "Random Forest, as an ensemble classifier, consists of many trees, with class output as the mode of individual trees. We find the optimal splits of data at each step in creating individual trees, with a bootstrap sample. These outputs are aggregated using Bootstrap Aggregation. \n",
    "\n",
    "We chose to use a Random Forest Model, due to it having the highest test set score. Random Forest Classifiers are also useful, in that we can get a sense of the importance of predictors, and it is good for large databases such as the ADNI one. It is also able to handle both binary and categorical variable types, without requiring scaling. Through optimizing for tree depth, as well as the formation of an individual tree, Random Forest Classifiers are also comparatively easy to train.\n",
    "\n",
    "Here, however, we will discuss several limitations of this model.\n",
    "\n",
    "First, the size of the Random Forest Classifier is rather large, in terms of memory requirements and computation. Additionally, there is a large risk of overfitting on the training data, particularly for noisy datasets. A common assumption for Random Forests is that the sampling is representative for the dataset.\n",
    "\n",
    "\n",
    "Generally, utilizing model imputation to predict the missing values (NaNs) can be a more accurate method to replace missing values, than either dropping NaNs or utilizing mean imputation. As previously mentioned, our approaches for model imputation were not valid given the large amount of missingness in this dataset. Specifically, a model fitted on the training data would be unable to be applied to the test data given large amount of, and differences in, missingness between the two datasets.\n",
    "\n",
    "A better methodology would be to take a circular approach to imputation, which would enable predicting missing values using a selected set of specific predictors, depending on which are available (not missing). However, in the context of this dataset, we would still need to utilize the test data beforehand, to determine the order of this circular methdology; thus, there is no way to approach model imputation without somehow incorporating the test set and creating a model specific to the data. We would further have to make some assumptions that in each iteration of imputing for a column, we would have to assume some independence of the variables we would be forced to ignore due to NaNs. As this seems too problematic an approach, we have moved forward with patient-level mean imputation.\n",
    "\n",
    "In regards to the methodology behind model imputation, we see that a large limitation is that we train the models on all non-missing predictors, which is extremely difficult given this data. Should this method have been successful, we could further improve our results by utilizing the new \"full models\": as new values are imputed, use these as \"non-missing\" too, such that we can train the model on as many other predictors as possible. Across many iterations, these values should eventually stabilize as we increase the set of existing values that can be used for prediction. Thus, it is a multi-stage procedure to accurately use linear regressions to predict the missing columns. \n",
    "\n",
    "\n",
    "Our method of imputation for missing values was to utilize patient-level means, or to impute missing values for the variable of interest by taking the mean of the patient's other observations. However, if the patient does not have any observations for the variable of interest (all are NaNs), then they are left as NaNs and therefore ultimately dropped from our dataset. Thus, a limitation of this approach is that imputing using patient-level means does not entirely address the issue of missing values because while we will be able to impute values for patients who have historical data for the variable of interest, those with all missing values will still be left with nans. \n",
    "\n",
    "In fact, the implication of this model is that when applying the model to future patients, the model will only work for participants with a complete set of predictor values; future patients who do not have any values for the predictors in our model cannot be used as we do not have a way to impute using other patients' information. This is the motivation to use an across-patient model for imputation; by using information from other patients to predict values for a given patient, we do not require that future patients will have all predictor values as we can predict missing ones using the model formed from the other patients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADNI Study Population, Use of Model\n",
    "\n",
    "Factors that we specifically analyze include patient demographics, to understand the balance of the dataset. We find that roughly half of the patients in the ADNI study are diagnosed with MCI, a quarter are diagnosed with Alzheimer’s Disease, and the remaining receive a Normal diagnosis. \n",
    "\n",
    "This class balance is not representative of the prevalence of AD in a random population sample, however, is beneficial for our purposes of examining the most important factors in determining the likelihood that a patient has developed Alzheimer's. Our model will be utilized on populations who are already showing symptoms of Alzheimer's, undergoing treatment, or otherwise have reason to obtain a diagnosis. These groups will have class balances closer to what we actually see in the ADNI dataset.\n",
    "\n",
    "Specifically, we have no patients in the data for switching from one classification to another (e.g. from MCI to AD, CN to MCI, or CN to AD), so there is no information regarding the time at which a person develops Alzheimer's, or changes from CN to AD. In other words, we are unable to examine disease progression in this dataset. Therefore, this classification model aims to acknowledge the fact that certain predictors take more time and energy (from both the hospital and the patient) to collect.\n",
    "\n",
    "We further incorporate the estimated costs that each predictor is associated with, which can be adjusted such that the model remains robust to these parameter changes. For instance, an MRI measure takes more money and time to collect than demographic data. For both the hospital and patient, this is important when considering the cost benefit tradeoffs. We consider the tradeoff between an accurate classification and cost, given that metrics such as brain imaging measures and biomarkers are often extremely costly to obtain. Thus, we want to find the model with the lowest cost possible by utilizing less expensive features, but also be accurate enough as to not incur misdiagnosis costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Works Cited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Davis, D. H., Creavin, S. T., Yip, J. L., Noel-Storr, A. H., Brayne, C., & Cullum, S. (2015). Montreal Cognitive Assessment for the diagnosis of Alzheimer’s disease and other dementias. Cochrane Database of Systematic Reviews. doi:10.1002/14651858.cd010775.pub2\n",
    "2. Karin, A., Hannesdottir, K., Jaeger, J., Annas, P., Segerdahl, M., Karlsson, P., . . . Miller, F. (2013). Psychometric evaluation of ADAS-Cog and NTB for measuring drug response. Acta Neurologica Scandinavica, 129(2), 114-122. doi:10.1111/ane.12153\n",
    "3. Llano, D. A., Laforet, G., & Devanarayan, V. (2011). Derivation of a New ADAS-cog Composite Using Tree-based Multivariate Analysis. Alzheimer Disease & Associated Disorders, 25(1), 73-84. doi:10.1097/wad.0b013e3181f5b8d8\n",
    "4. Mayo Clinic. Alzheimer's disease. (2017, August 11). Retrieved December 05, 2017, from https://www.mayoclinic.org/diseases-conditions/alzheimers-disease/symptoms-causes/syc-20350447\n",
    "5. Michaelson, D. M. (2014). APOE ε4: The most prevalent yet understudied risk factor for Alzheimers disease. Alzheimers & Dementia, 10(6), 861-868. doi:10.1016/j.jalz.2014.06.015\n",
    "6. Moradi, E., Hallikainen, I., Hänninen, T., Tohka, J., & Alzheimer’s Disease Neuroimaging Initiative. (2017). Rey’s Auditory Verbal Learning Test scores can be predicted from whole brain MRI in Alzheimer’s disease. NeuroImage : Clinical, 13, 415–427. http://doi.org/10.1016/j.nicl.2016.12.011\n",
    "7. Nazeri, A., Ganjgahi, H., Roostaei, T., Nichols, T., & Zarei, M. (2014). Imaging proteomics for diagnosis, monitoring and prediction of Alzheimers disease. NeuroImage, 102, 657-665. doi:10.1016/j.neuroimage.2014.08.041\n",
    "8. Park, L. Q., Harvey, D., Johnson, J., & Farias, S. T. (2015). Deficits in everyday function differ in AD and FTD. Alzheimer Disease and Associated Disorders, 29(4), 301–306. http://doi.org/10.1097/WAD.0000000000000081\n",
    "9. Pradier, C., Sakarovitch, C., Le Duff, F., Layese, R., Metelkina, A., Anthony, S., … Robert, P. (2014). The Mini Mental State Examination at the Time of Alzheimer’s Disease and Related Disorders Diagnosis, According to Age, Education, Gender and Place of Residence: A Cross-Sectional Study among the French National Alzheimer Database. PLoS ONE, 9(8), e103630. http://doi.org/10.1371/journal.pone.0103630\n",
    "10. Rueda, A., Lau, K., Saito, N., Harvey, D., Risacher, S., Aisen, P., … Alzheimer’s Disease Neuroimaging Initiative. (2015). Self-rated and informant-rated everyday function in comparison to objective markers of Alzheimer’s disease. Alzheimer’s & Dementia : The Journal of the Alzheimer’s Association, 11(9), 1080–1089. http://doi.org/10.1016/j.jalz.2014.09.002\n",
    "11. Ungar, L., Altmann, A., & Greicius, M. D. (2014). Apolipoprotein E, Gender, and Alzheimer’s Disease: An Overlooked, but Potent and Promising Interaction. Brain Imaging and Behavior, 8(2), 262–273. http://doi.org/10.1007/s11682-013-9272-x\n",
    "12. Vemuri, P., & Jack, C. R., Jr. (2010). Role of structural MRI in Alzheimer's disease. Alzheimer's Research & Therapy, 2(33). Retrieved December 5, 2017, from https://alzres.biomedcentral.com/articles/10.1186/alzrt47.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
